import { ChatOpenAI } from "@langchain/openai";
import { PromptTemplate } from "@langchain/core/prompts";
import { RunnableSequence } from "@langchain/core/runnables";
import { StringOutputParser } from "@langchain/core/output_parsers";

export async function runPersonalAgent({
  prompt,
  profile,
}: {
  prompt: string;
  profile: string;
}) {
  const systemMessage = `×”×™×™ ğŸ¤—

××ª×” ×¡×•×›×Ÿ ××™×©×™ ×©××›×™×¨ ×œ×¢×•××§ ××ª ×©×™×œ×” ××œ×§×•×‘×™ â€“ ×’× ××ª ×”×“×¨×š ×©×¢×‘×¨, ×’× ××ª ×”××ª×’×¨×™× ×©×—×•×•×”, ×•×’× ××ª ×”×“×‘×¨×™× ×©×× ×™×¢×™× ××•×ª×• ×‘×××ª.

×”×ª×¤×§×™×“ ×©×œ×š ×”×•× ×œ×¢× ×•×ª ×œ×©××œ×•×ª ×›××™×œ×• ××ª×” ×—×‘×¨ ×§×¨×•×‘ ×©××›×‘×“ ××ª ×©×™×œ×” ×•××“×‘×¨ ×¢×œ×™×• ××”×œ×‘.

×“×‘×¨ ×‘×¦×•×¨×” ×× ×•×©×™×ª, ×¨×’×™×©×”, ×××¤×ª×™×ª â€“ ×‘×’×•×‘×” ×”×¢×™× ×™×™×.  
×× ××ª××™× â€“ ×ª×•×›×œ ×œ×©×œ×‘ ×”×•××•×¨ ×¢×“×™×Ÿ, ×¤×¨×’×•×Ÿ, ××• ××™×œ×” ×˜×•×‘×”.  
××œ ×ª× ×—×© ×“×‘×¨×™× ×©×œ× ×›×ª×•×‘×™× ×‘×¤×¨×•×¤×™×œ â€“ ×¨×§ ×ª×ª×‘×¡×¡ ×¢×œ×™×•, ××‘×œ ×ª×“×‘×¨ ×›××• ××“×, ×œ× ×›××• ×¨×•×‘×•×˜.

×× ×©×•××œ×™× "××” ×©×œ×•××š" ××• ×©××œ×” ×›×œ×œ×™×ª â€“ ××¤×©×¨ ×œ×”×ª×™×™×—×¡ ×’× ×œ×ª×—×•×©×•×ª ××• × ×§×•×“×ª ××‘×˜ ×©××•×¤×™×¢×” ×‘××¡××š.

×ª×¢× ×” ×‘×©×¤×” ×©×‘×” × ×©××œ×ª ×”×©××œ×” â€“ ×•×× ×‘×¢×‘×¨×™×ª, ×ª×¢× ×” ×‘×¢×‘×¨×™×ª ×–×•×¨××ª.
×”× ×” ×”×¤×¨×•×¤×™×œ ×©×œ ×©×™×œ×”:
${profile}

`;

  const promptTemplate = PromptTemplate.fromTemplate(
    `${systemMessage}\n\n×©××œ×”: {prompt}\n×ª×©×•×‘×”:`
  );

  const model = new ChatOpenAI({
    modelName: "gpt-3.5-turbo",
    temperature: 0.3,
    streaming: false,
  });

  const chain = RunnableSequence.from([
    promptTemplate,
    model,
    new StringOutputParser(),
  ]);

  return await chain.invoke({ prompt });
}
